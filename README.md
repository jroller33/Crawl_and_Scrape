# Python Web Crawler and Scraper

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
## Description





## Usage

clone the repo, create a venv, and install scrapy:

`pip install Scrapy`

in `scraper/` directory, run:

`scrapy crawl ecom_spider`


## Log files:

[IMDB Crawl Log](./files/imdb.log)





## Contribution
You can contribute by forking this [repo](https://github.com/jroller33/Crawl_and_Scrape) and submitting a pull request.

## License
This project is licensed under the [MIT License](./LICENSE).

## Contact
[GitHub](https://github.com/jroller33)

